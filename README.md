ğŸš€ Arxiv RAG Bot â€“ Enhanced Version

This project is based on the original notebook:
ğŸ‘‰ Hadi-Kassem/Arxiv-RAG-bot
https://github.com/Hadi-Kassem/Arxiv-RAG-bot/blob/main/main.ipynb

Iâ€™ve added several enhancements to make it run significantly faster on my local machine (Windows, 16 GB RAM, Intel Core i7).
â± Response time is now 10â€“15 seconds, compared to the original ~2 minutes.

ğŸ”‘ Key Improvements
âš¡ Switched Models

Replaced Mistral with LLaMA for better performance on CPU.

ğŸ¯ Fine-Tuned Parameters

Adjusted temperature and num_predict for faster and more relevant responses.

ğŸ“š Smart Context Handling

Added summarization for long contexts to keep responses concise and efficient.

ğŸ§  Prompt Engineering

Improved prompts to increase accuracy and reduce unnecessary output.

ğŸ”® Future Enhancements

ğŸ“‘ Smart Chunking â†’ Implement intelligent document splitting to improve retrieval accuracy and context management.

ğŸ’¾ Caching â†’ Store and reuse frequent queries to reduce response time even further.

ğŸ‹ï¸ Model Fine-Tuning â†’ Train the model on 5,000 questionâ€“answer pairs generated from a larger model (e.g., ChatGPT), using Unsloth on Google Colab for efficient fine-tuning.
